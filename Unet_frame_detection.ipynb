{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet-frame-detection",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexflames/frame-detection/blob/master/Unet_frame_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHIx763vuCLy",
        "colab_type": "text"
      },
      "source": [
        "## Автор\n",
        "Григорьев Алексей, 451 группа, КНиИТ\n",
        "\n",
        "## Задание\n",
        "С помощью машинного обучения научиться различать рамки у картин для последующего вырезания и превращения изображений картин с рамками в картины **без** рамок\n",
        "\n",
        "### Часть 2 - решение с использованием Unet\n",
        "##### **\"Простой\" набор данных**\n",
        "[Первый набор данных](https://drive.google.com/open?id=19Wx9l9C6IovJ5n1OTYzmt39w5cmIgzHJ) представляет 200 \"простых для обработки\" изображений картин с рамками,\n",
        "собраны в поисковике google, посредством отфильтрации подходящих вручную.\n",
        "- **Все** картины имеют рамки;\n",
        "- Картины **не** повернуты под углом;\n",
        "- Может быть свободное пространство любого цвета **до** рамки, **после** рамки перед изображением;\n",
        "- Рамки преимущественно монотонные, но также иногда встречаются объмные варианты;\n",
        "- Возможно наличие теней или других эффектов окружающего мира на центральной части изображения / с какой-то стороны от картины;\n",
        "- Форматы изображений `.jpg | .png | .webp`;\n",
        "- Изображения разных размеров, разное соотношение сторон;\n",
        "- Различная цветовая гамма.\n",
        "\n",
        "##### **Материал**\n",
        "- [Использование Unet для решения своей задачи](https://medium.com/coinmonks/learn-how-to-train-u-net-on-your-dataset-8e3f89fbd623)\n",
        "- [Гит-репозитории в Google Colab](https://medium.com/@ashwindesilva/how-to-use-google-colaboratory-to-clone-a-github-repository-e07cf8d3d22b)\n",
        "- [Оригинальный репозиторий с Unet](https://github.com/zhixuhao/unet)\n",
        "- [Подходящая версия под первую статью](https://github.com/zhixuhao/unet/commit/4b939a4dbd930eeaf3d6fffcb514860cb11c948d)\n",
        "\n",
        "##### **Программа**\n",
        "Далее следуют фрагменты программы для решения задачи\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVHk7om2xVFo",
        "colab_type": "text"
      },
      "source": [
        "**Шаг №1**\n",
        "\n",
        "Подключаем гугл-диск, клонируем мой форк оригинального Unet-репозитория\n",
        "Форк необходим так как код немного модифицирован, ветка frame-detection создана из коммита *4b939a4dbd930eeaf3d6fffcb514860cb11c948d*\n",
        "\n",
        "В ней заменены некоторые `.py` исходники в соответствии со статьей выше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUu-I2CQyyzm",
        "colab_type": "code",
        "outputId": "458ff508-bd25-4703-a8c7-f8b9eb28e510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "print(\"Если код выводит ошибки типа [Errno 2], игнорируйте их. Эти ошибки не мешают выполнению программы\\n\")\n",
        "drive.mount('/content/gdrive')\n",
        "! ls\n",
        "# Замените путь после 'My Drive' на ваш собственный путь с проектом и данными\n",
        "%cd gdrive/My Drive/Studies2/ML\n",
        "# следующий фрагмент необходимо использовать только 1 раз в Вашем гугл-диске!!!\n",
        "#! git clone https://github.com/Alexflames/unet.git\n",
        "%cd unet\n",
        "! git pull\n",
        "! git checkout frame-detection\n",
        "! git branch\n",
        "%cd .."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Если код выводит ошибки типа [Errno 2], игнорируйте их. Эти ошибки не мешают выполнению программы\n",
            "\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n",
            "/content/gdrive/My Drive/Studies2/ML\n",
            "/content/gdrive/My Drive/Studies2/ML/unet\n",
            "Already up to date.\n",
            "M\tdata/test/0.tif\n",
            "M\tdata/test/1.tif\n",
            "M\tdata/test/10.tif\n",
            "M\tdata/test/11.tif\n",
            "M\tdata/test/12.tif\n",
            "M\tdata/test/13.tif\n",
            "D\tdata/test/14.tif\n",
            "D\tdata/test/15.tif\n",
            "D\tdata/test/16.tif\n",
            "D\tdata/test/17.tif\n",
            "D\tdata/test/18.tif\n",
            "D\tdata/test/19.tif\n",
            "M\tdata/test/2.tif\n",
            "D\tdata/test/20.tif\n",
            "D\tdata/test/21.tif\n",
            "D\tdata/test/22.tif\n",
            "D\tdata/test/23.tif\n",
            "D\tdata/test/24.tif\n",
            "D\tdata/test/25.tif\n",
            "D\tdata/test/26.tif\n",
            "D\tdata/test/27.tif\n",
            "D\tdata/test/28.tif\n",
            "D\tdata/test/29.tif\n",
            "M\tdata/test/3.tif\n",
            "M\tdata/test/4.tif\n",
            "M\tdata/test/5.tif\n",
            "M\tdata/test/6.tif\n",
            "M\tdata/test/7.tif\n",
            "M\tdata/test/8.tif\n",
            "M\tdata/test/9.tif\n",
            "D\tdata/train/image/0.tif\n",
            "D\tdata/train/image/1.tif\n",
            "D\tdata/train/image/10.tif\n",
            "D\tdata/train/image/11.tif\n",
            "D\tdata/train/image/12.tif\n",
            "D\tdata/train/image/13.tif\n",
            "D\tdata/train/image/14.tif\n",
            "D\tdata/train/image/15.tif\n",
            "D\tdata/train/image/16.tif\n",
            "D\tdata/train/image/17.tif\n",
            "D\tdata/train/image/18.tif\n",
            "D\tdata/train/image/19.tif\n",
            "D\tdata/train/image/2.tif\n",
            "D\tdata/train/image/20.tif\n",
            "D\tdata/train/image/21.tif\n",
            "D\tdata/train/image/22.tif\n",
            "D\tdata/train/image/23.tif\n",
            "D\tdata/train/image/24.tif\n",
            "D\tdata/train/image/25.tif\n",
            "D\tdata/train/image/26.tif\n",
            "D\tdata/train/image/27.tif\n",
            "D\tdata/train/image/28.tif\n",
            "D\tdata/train/image/29.tif\n",
            "D\tdata/train/image/3.tif\n",
            "D\tdata/train/image/4.tif\n",
            "D\tdata/train/image/5.tif\n",
            "D\tdata/train/image/6.tif\n",
            "D\tdata/train/image/7.tif\n",
            "D\tdata/train/image/8.tif\n",
            "D\tdata/train/image/9.tif\n",
            "D\tdata/train/label/0.tif\n",
            "D\tdata/train/label/1.tif\n",
            "D\tdata/train/label/10.tif\n",
            "D\tdata/train/label/11.tif\n",
            "D\tdata/train/label/12.tif\n",
            "D\tdata/train/label/13.tif\n",
            "D\tdata/train/label/14.tif\n",
            "D\tdata/train/label/15.tif\n",
            "D\tdata/train/label/16.tif\n",
            "D\tdata/train/label/17.tif\n",
            "D\tdata/train/label/18.tif\n",
            "D\tdata/train/label/19.tif\n",
            "D\tdata/train/label/2.tif\n",
            "D\tdata/train/label/20.tif\n",
            "D\tdata/train/label/21.tif\n",
            "D\tdata/train/label/22.tif\n",
            "D\tdata/train/label/23.tif\n",
            "D\tdata/train/label/24.tif\n",
            "D\tdata/train/label/25.tif\n",
            "D\tdata/train/label/26.tif\n",
            "D\tdata/train/label/27.tif\n",
            "D\tdata/train/label/28.tif\n",
            "D\tdata/train/label/29.tif\n",
            "D\tdata/train/label/3.tif\n",
            "D\tdata/train/label/4.tif\n",
            "D\tdata/train/label/5.tif\n",
            "D\tdata/train/label/6.tif\n",
            "D\tdata/train/label/7.tif\n",
            "D\tdata/train/label/8.tif\n",
            "D\tdata/train/label/9.tif\n",
            "Already on 'frame-detection'\n",
            "Your branch is up to date with 'origin/frame-detection'.\n",
            "* \u001b[32mframe-detection\u001b[m\n",
            "  master\u001b[m\n",
            "/content/gdrive/My Drive/Studies2/ML\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GjzIhu2Q7t3",
        "colab_type": "text"
      },
      "source": [
        "#### **Шаг №2: Подготовка изображений**\n",
        "Приведение их к одинаковому размеру\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vc7RUYe7fgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Подготовка изображений!\n",
        "# Необходимо раскомментировать самую нижнюю строку чтобы запустить\n",
        "from PIL import Image\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import manifold, datasets\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Следующие 2 функции для ресайза изображения и дополнения до квадрата\n",
        "# Взято из 3 практики по ML\n",
        "def add_pad(img, shape):\n",
        "    color_pick = img[0][0]\n",
        "    padded_img = color_pick * np.ones(shape + img.shape[2:3], dtype=np.uint8)\n",
        "    x_offset = int((padded_img.shape[0] - img.shape[0]) / 2)\n",
        "    y_offset = int((padded_img.shape[1] - img.shape[1]) / 2)\n",
        "    padded_img[x_offset:x_offset + img.shape[0], y_offset:y_offset + img.shape[1]] = img\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def resize(img, shape):\n",
        "    scale = min(shape[0] * 1.0 / img.shape[0], shape[1] * 1.0 / img.shape[1])\n",
        "    if scale != 1:\n",
        "        img = cv2.resize(img, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
        "    return img\n",
        "\n",
        "\n",
        "def prepare_images(path_from, path_save_to):\n",
        "  for i, file in enumerate(os.listdir(path_from)):\n",
        "    if not file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "      continue\n",
        "    img = io.imread(path_from + '/' + file)\n",
        "    #Subsection of the image\n",
        "    img = resize(img, (512, 512))\n",
        "    img = add_pad(img, (512, 512))\n",
        "\n",
        "    path = str(i) + '.tif'\n",
        "    io.imsave(path_save_to + '/' + path, img)\n",
        "\n",
        "prepare_images(\"image_dataset_unet\", \"unet/data/train/image\")\n",
        "prepare_images(\"labels_dataset_unet\", \"unet/data/train/label\")\n",
        "prepare_images(\"test_dataset_unet\", \"unet/data/test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKV9CIjKkcSF",
        "colab_type": "text"
      },
      "source": [
        "[Ссылка на data.py - подготовка данных](https://github.com/Alexflames/unet/blob/frame-detection/data.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP-nnFFB8Fw0",
        "colab_type": "code",
        "outputId": "08fbba09-cc74-41f1-8af4-9b13dffc0127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!python unet/data.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "------------------------------\n",
            "Creating training images...\n",
            "------------------------------\n",
            "31\n",
            "Done: 0/31 images\n",
            "loading done\n",
            "Saving to .npy files done.\n",
            "------------------------------\n",
            "Creating test images...\n",
            "------------------------------\n",
            "14\n",
            "loading done\n",
            "Saving to imgs_test.npy files done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28VsfwS9WzC4",
        "colab_type": "text"
      },
      "source": [
        "[Ссылка на unet.py - обучение и запуск сетки unet](https://github.com/Alexflames/unet/blob/frame-detection/unet.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhS3UlQRXADs",
        "colab_type": "code",
        "outputId": "e430c3e1-38b3-4f99-c44e-6d0944921380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python unet/unet.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "loading data\n",
            "------------------------------\n",
            "load train images...\n",
            "------------------------------\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "loading data done\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "conv1 shape: (?, 512, 512, 64)\n",
            "conv1 shape: (?, 512, 512, 64)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "pool1 shape: (?, 256, 256, 64)\n",
            "conv2 shape: (?, 256, 256, 128)\n",
            "conv2 shape: (?, 256, 256, 128)\n",
            "pool2 shape: (?, 128, 128, 128)\n",
            "conv3 shape: (?, 128, 128, 256)\n",
            "conv3 shape: (?, 128, 128, 256)\n",
            "pool3 shape: (?, 64, 64, 256)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "unet/unet.py:143: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
            "  model = Model(input = inputs, output = conv10)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "got unet\n",
            "Fitting model...\n",
            "unet/unet.py:160: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  model.fit(imgs_train, imgs_mask_train, batch_size=4, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 24 samples, validate on 7 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-11-27 14:22:25.211903: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-11-27 14:22:25.212470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1512bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-27 14:22:25.212515: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-27 14:22:25.221054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-27 14:22:25.368962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-27 14:22:25.369963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1512d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-27 14:22:25.370008: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-11-27 14:22:25.371376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-27 14:22:25.372106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-27 14:22:25.389093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-11-27 14:22:25.670676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-11-27 14:22:25.828611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-11-27 14:22:25.862793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-11-27 14:22:26.122577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-11-27 14:22:26.151212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-11-27 14:22:26.671009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-27 14:22:26.671260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-27 14:22:26.672120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-27 14:22:26.672857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-27 14:22:26.676506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-11-27 14:22:26.678008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-27 14:22:26.678043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-27 14:22:26.678069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-27 14:22:26.679453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-27 14:22:26.680366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-27 14:22:26.681079: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-11-27 14:22:26.681140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2019-11-27 14:22:31.877349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-27 14:22:34.770449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "24/24 [==============================] - 58s 2s/step - loss: 0.6966 - acc: 0.7757 - val_loss: 0.6929 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.69659, saving model to unet.hdf5\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 18s 765ms/step - loss: 0.6928 - acc: 0.9236 - val_loss: 0.6926 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00002: loss improved from 0.69659 to 0.69279, saving model to unet.hdf5\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 19s 774ms/step - loss: 0.6925 - acc: 0.9236 - val_loss: 0.6923 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00003: loss improved from 0.69279 to 0.69253, saving model to unet.hdf5\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 18s 770ms/step - loss: 0.6923 - acc: 0.9236 - val_loss: 0.6921 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00004: loss improved from 0.69253 to 0.69229, saving model to unet.hdf5\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 19s 775ms/step - loss: 0.6920 - acc: 0.9236 - val_loss: 0.6918 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00005: loss improved from 0.69229 to 0.69203, saving model to unet.hdf5\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 18s 765ms/step - loss: 0.6918 - acc: 0.9236 - val_loss: 0.6915 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00006: loss improved from 0.69203 to 0.69178, saving model to unet.hdf5\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 19s 772ms/step - loss: 0.6915 - acc: 0.9236 - val_loss: 0.6912 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00007: loss improved from 0.69178 to 0.69153, saving model to unet.hdf5\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 18s 765ms/step - loss: 0.6913 - acc: 0.9236 - val_loss: 0.6909 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00008: loss improved from 0.69153 to 0.69127, saving model to unet.hdf5\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 19s 775ms/step - loss: 0.6910 - acc: 0.9236 - val_loss: 0.6907 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00009: loss improved from 0.69127 to 0.69102, saving model to unet.hdf5\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 18s 763ms/step - loss: 0.6908 - acc: 0.9236 - val_loss: 0.6904 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00010: loss improved from 0.69102 to 0.69077, saving model to unet.hdf5\n",
            "predict test data\n",
            "14/14 [==============================] - 7s 500ms/step\n",
            "array to image\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}